# Robots.txt в ZedCMS #

Robots.txt это обычный текстовый файл, который должен быть доступен по URL **/robots.txt**. Его запрашивают поисковые системы и другие роботы, которые сканируют ваш сайт.

# Функция Robots.txt #
Robots.txt служит для ограничения доступа внешних роботов к вашему сайту, с помощью него можно скрыть от поисковых систем определенные страницы или целые разделы сайта, или же весь сайт.
[Более подробно о robots.txt](http://robotstxt.org.ru/)

# Конфигурация и местоположение robots.txt #
В ZedCMS предусмотрена возможность нескольких версий **robots.txt**. Это может быть нужно для [трехландшафтной архитектуры](ThreeLandscape.md). Например, для сайта разработки нам неоходимо "отдавать" **robots.txt**, который будет запрещать доступ поисковых роботов ко всему сайту, а в продуктивной версии нам необходимы другие правила, которые, например, откроют доступ к сайту, но закроют его к административной части.

Таким образом, у нас может быть несколько версий **robots.txt**, которые должны размещаться в **/configs/** нашего сайта. Например, будет два файла:
  * **robots\_prod.txt**
  * **robots\_dev.txt**

Каждый из них будет содержать соответствующие правила:

**robots\_prod.txt**:

```
User-agent: *
Disallow: /ajax/
Disallow: /moy-cabinet/
Disallow: /captcha.php
Disallow: /redirect.php
```

**robots\_dev.txt:**

```
User-agent: *
Disallow: /
```

Теперь зададим в [конфигурации сайта](SiteConfiguration.md) использование этих файлов.
Фрагмент config.ini:
```
[default]
    robots.txt = "robots_dev.txt"
[www.site1.com]
    robots.txt = "robots_prod.txt"
```

Таким образом, по умолчанию по URL адресу **/robots.txt** будет отдаваться файл **robots\_dev.txt**, который запрещает доступ роботов к сайту. А на домене **www.site1.com** будет отдаваться robots\_prod.txt, который запрещает доступ только лишь к определенным страницам сайта.